# Sign Language Learning Application

### Overview
Communication is a crucial aspect of daily life. For individuals with hearing and speech impairments, sign language serves as a primary means of communication, allowing them to interact with the world around them. However, learning sign language can be challenging due to limited access to resources and lack of interactivity, making the learning process less effective and engaging.

To address these challenges, we have designed **SignEase**, a technology-based application that utilizes artificial intelligence (AI) to assist individuals with hearing and speech impairments in learning sign language. By using gesture recognition technology, SignEaser provides an interactive and enjoyable learning experience for its users.

 **SignEase** is a machine learning-powered application designed to assist individuals with hearing and speech impairments in learning sign language. The application utilizes video classification to interpret sign language gestures and provides users with interactive lessons and feedback. By leveraging machine learning algorithms,  SignEase aims to make learning sign language accessible, engaging, and effective

### Team Members
- **Fiki Aprian**
  - **Role:** ML and Backend Developer
  - **Interests & Activities:** Passionate about machine learning and cloud computing, with a focus on developing solutions for social impact.
  - **Portfolio:** https://my-portofolio-fikiap23.vercel.app
  - **LinkedIn:** [Fiki Aprian](https://www.linkedin.com/in/fiki-aprian-b8624b216/)
  - **GitHub:** [https://github.com/fikiap23](https://github.com/fikiap23)

- **Megan Madelin**
  - **Role:** Frontend Developer
  - **Interests & Activities:** Interested in creating user-friendly interfaces and accessible web applications.
  - **Portfolio:** [Portfolio URL]
  - **LinkedIn:** [LinkedIn URL]
  - **GitHub:** [GitHub URL]

- **Anissa Tri Lahitani**
  - **Role:** ML Developer
  - **Interests & Activities:** Passionate about machine learning applications for social good.
  - **Portfolio:** https://lahitanido26.github.io/MyPortofolio/
  - **LinkedIn:** [Anissa Tri Lahitani](www.linkedin.com/in/anissa-tri-lahitani
)
  - **GitHub:** [https://github.com/lahitanido26](https://github.com/lahitanido26)

- **Mohammad Ezra Nur Islami**
  - **Role:** ML Developer
  - **Interests & Activities:** Interested in developing machine learning solutions to address real-world challenges.
  - **Portfolio:** https://heyzra.github.io/hizra.github.io/
  - **LinkedIn:** [Mohammad Ezra Nur Islami](https://www.linkedin.com/in/mohammad-ezra/)
  - **GitHub:** [https://github.com/heyZra](v)

### Topic and Motivation
The motivation behind  SignEase stems from the desire to bridge the communication gap for individuals with hearing and speech impairments. Sign language is a vital form of communication for this community, yet resources for learning can be limited and inaccessible. By developing a machine learning application that teaches sign language in an engaging and interactive manner, we aim to empower individuals with hearing and speech impairments to learn and communicate effectively.

### Target User Group
SignEaser is designed for individuals with hearing and speech impairments who are interested in learning sign language. The application is suitable for users of all ages and backgrounds who wish to improve their communication skills and broaden their understanding of sign language.

### Proposed Solution

#### Product Branding
The product will be branded as "SignEase," symbolizing its goal of making sign language communication easier and more accessible for everyone.

#### Description
"SignEase" offers a comprehensive platform for learning sign language through interactive lessons, quizzes, and practice exercises. The application uses machine learning algorithms to interpret and analyze users' sign language gestures, providing real-time feedback and suggestions for improvement. By incorporating gamification elements and personalized learning paths, SignEase aims to make the learning process engaging, effective, and enjoyable

#### How This Project Relates to SDGs
This project aligns with several Sustainable Development Goals (SDGs), including:
- Goal 3: Good Health and Well-being, by improving communication access for individuals with hearing impairments.
- Goal 4: Quality Education, SignEase promotes inclusive and equitable education by providing accessible resources for individuals with hearing and speech impairments to learn sign language..
- Goal 10: Reduced Inequalities, By facilitating communication and understanding for individuals with hearing and speech impairments, SignEase contributes to reducing inequalities and promoting social inclusion.

#### Application Flow Chart

#### Application Design and Illustration

### Research Questions and Objectives
*   **Research Question:** How can machine learning algorithms be effectively utilized to facilitate the learning of sign language?
*   **Objectives:**
    1.  Develop a machine learning model capable of recognizing and interpreting sign language gestures.
    2.  Create an interactive and user-friendly application interface for learning sign language.
    3.  Evaluate the effectiveness of the application in improving users' sign language skills and communication abilities.

### Research Methodology
The research methodology for SignEase includes:

*   Data Collection: Gathering a diverse dataset of sign language gestures for training the machine learning model.
*   Model Development: Training and optimizing a machine learning model for sign language gesture recognition.
*   Application Development: Designing and implementing the application interface for SignEase.
*   User Testing: Conducting usability testing and gathering feedback from users to improve the application.

### Methods and Technologies
- TensorFlow, scikit-learn for machine learning model development
- NestJs, Prisma, PostgresSQL for backend development
- Flask for backend ML (Deploy Model)
- React for frontend development web
- Kotlin for mobile frontend development 

### Time Tables
*   **Phase 1: Research and Planning (Month 1)**
    
    *   Conduct research on sign language recognition and machine learning algorithms.
    *   Define project requirements and objectives.
    *   Plan the development and implementation strategy.
*   **Phase 2: Development (Months 2-4)**
    
    *   Develop the machine learning model for sign language recognition.
    *   Implement the frontend and backend components of the application.
    *   Integrate the machine learning model into the application interface.
*   **Phase 3: Testing and Evaluation (Months 5-6)**
    
    *   Conduct user testing and gather feedback for improvement.
    *   Evaluate the effectiveness of the application in learning sign language.
    *   Make final adjustments and refinements based on feedback.

### References

### Additional Pages

### GitHub Repository
